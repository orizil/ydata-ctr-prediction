{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, Feature Engineering, Model Selection - 1st Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import holidays\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the initial EDA (which can be found in the EDA notebook), we will now perform the following steps:\n",
    "1. Preprocess the data: data impuation, data transformation, data normalization\n",
    "2. Feature addition: add lots of new features (interaction, encoding, binning...) \n",
    "3. Feature selection- Statistical validation tests: perform statistical tests to see if the new features are useful.\n",
    "4. Feature selection- cross validation tests: perform cross validation to see if the new features are useful.\n",
    "5. Model selection: try different models and see which one performs the best.\n",
    "6. Model tuning: tune the best model to see if we can improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean the data\n",
    "\n",
    "filepath = \"train_dataset_full.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "\n",
    "# clean the data\n",
    "def clean_data(df):\n",
    "    # remove entirely empty rows and fully duplicate rows\n",
    "    df = df.dropna(how=\"all\").drop_duplicates()\n",
    "    \n",
    "    # ensure the DateTime column is in datetime format\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "\n",
    "    # ensure values that are supposed to be ints are indeed so (and not unnecessarily floats)\n",
    "    int_columns = ['campaign_id', 'webpage_id', 'product_category_1',\n",
    "                   'age_level', 'user_depth', 'city_development_index']\n",
    "    for col in int_columns:\n",
    "        df[col] = df[col].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation\n",
    "\n",
    "In the EDA, the missing values that stood out were in:\n",
    "1. \"product_category_2\" (79.16% missing): we will creates a missing indicator feature (which might get dropped in future steps if deemed irrelevant) but won't impute values, as that could introduce misleading data, as there's simply too much missing data. \n",
    "2. \"city_development_index\" (27.60%): we will creates a missing indicator feature (which might get dropped in future steps if deemed irrelevant) and impute with the mode.\n",
    "3. \"gender\", \"age_level\", \"user_depth\", \"user_group_id\": we will first attempt to fill from other sessions of the same user, but we'll fallback to global defaults as needed.\n",
    "4. Else: we will automatically impute missing values for features with missing rates below 1%, using the mode for categorical variables (including those with low cardinality), and medians for numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_demographics_by_user(df):\n",
    "    \"\"\"\n",
    "    Imputes demographic features (gender, age_level, user_depth) using other \n",
    "    sessions from the same user when available, then falls back to global defaults.\n",
    "    \n",
    "    The EDA showed these features have about 4.7% missing values and are generally\n",
    "    consistent within users, making this a reliable approach.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # first, attempt to fill missing demographics using other sessions from same user\n",
    "    demographics = ['gender', 'age_level', 'user_depth', 'user_group_id']\n",
    "    \n",
    "    for demo in demographics:\n",
    "        # group by user_id and apply forward fill and backward fill\n",
    "        df[demo] = df.groupby('user_id')[demo].transform(\n",
    "            lambda x: x.ffill().bfill()\n",
    "        )\n",
    "    \n",
    "    # if there are any remaining missing values, fill with mode values:\n",
    "    defaults = {\"gender\": df[\"gender\"].mode().iloc[0],\n",
    "                \"age_level\": df[\"age_level\"].mode().iloc[0],\n",
    "                \"user_depth\": df[\"user_depth\"].mode().iloc[0],\n",
    "                \"user_group_id\": df[\"user_group_id\"].mode().iloc[0]}\n",
    "\n",
    "    \n",
    "    for column, default in defaults.items():\n",
    "        df[column] = df[column].fillna(default)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_product_category2(df):\n",
    "    \"\"\"\n",
    "    Handles product_category_2 which has 79.16% missing values.\n",
    "    Creates a binary indicator for missingness and leaves original values as is.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # create missing indicator\n",
    "    df['product_category_2_missing'] = df['product_category_2'].isna().astype(int)\n",
    "    \n",
    "    # return without imputing due to extremely high missingness\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_city_development(df):\n",
    "    \"\"\"\n",
    "    Handles city_development_index which has 27.60% missing values.\n",
    "    Creates a missing indicator and imputes with mode.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # create missing indicator\n",
    "    df['city_development_missing'] = df['city_development_index'].isna().astype(int)\n",
    "    \n",
    "    # impute with mode\n",
    "    city_development_mode = df['city_development_index'].mode()[0]\n",
    "    df['city_development_index'] = df['city_development_index'].fillna(city_development_mode)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_low_missing(df, threshold: float=0.01):\n",
    "    \"\"\"\n",
    "    Handles features with low missing rates (< threshold).\n",
    "    Uses mode for categorical variables and median for numerical ones.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # identify columns with low missing rates\n",
    "    missing_rates = df.isnull().mean()\n",
    "    low_missing_cols = missing_rates[missing_rates > 0][missing_rates < threshold].index\n",
    "    \n",
    "    for col in low_missing_cols:\n",
    "        # determine if column should be treated as categorical\n",
    "        unique_vals = df[col].nunique()\n",
    "        is_categorical = pd.api.types.is_object_dtype(df[col]) or unique_vals <= 10\n",
    "        \n",
    "        if is_categorical:\n",
    "            # for categorical variables, use mode\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:\n",
    "            # for numerical variables, use median\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def impute_dataset(df):\n",
    "    \"\"\"\n",
    "    Applies the complete imputation pipeline to the dataset.\n",
    "    Returns a new dataframe with all imputation strategies applied.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # apply each imputation step in sequence\n",
    "    df = impute_demographics_by_user(df)\n",
    "    df = handle_product_category2(df)\n",
    "    df = handle_city_development(df)\n",
    "    df = handle_low_missing(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df_imputed = impute_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation of the imputation: looking at column distributions changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "session_id:\n",
      "Mean - Original: 285452.08, Imputed: 285451.90\n",
      "Std  - Original: 168593.35, Imputed: 167914.47\n",
      "\n",
      "user_id:\n",
      "Mean - Original: 545905.09, Imputed: 545790.67\n",
      "Std  - Original: 329529.65, Imputed: 328225.35\n",
      "\n",
      "product distribution:\n",
      "Original vs Imputed:\n",
      "         Original   Imputed\n",
      "product                    \n",
      "C        0.353391  0.358681\n",
      "H        0.235999  0.234069\n",
      "I        0.137374  0.136250\n",
      "D        0.088477  0.087753\n",
      "B        0.048436  0.048040\n",
      "\n",
      "campaign_id:\n",
      "Mean - Original: 308547.20, Imputed: 308968.33\n",
      "Std  - Original: 126502.49, Imputed: 126063.30\n",
      "\n",
      "webpage_id:\n",
      "Mean - Original: 29699.44, Imputed: 29569.53\n",
      "Std  - Original: 21548.50, Imputed: 21508.07\n",
      "\n",
      "product_category_1:\n",
      "Mean - Original: 3.07, Imputed: 3.08\n",
      "Std  - Original: 1.30, Imputed: 1.30\n",
      "\n",
      "user_group_id:\n",
      "Mean - Original: 3.48, Imputed: 3.46\n",
      "Std  - Original: 2.42, Imputed: 2.36\n",
      "\n",
      "gender distribution:\n",
      "Original vs Imputed:\n",
      "        Original   Imputed\n",
      "gender                    \n",
      "Male    0.883568  0.889101\n",
      "Female  0.116432  0.110899\n",
      "\n",
      "age_level:\n",
      "Mean - Original: 2.78, Imputed: 2.79\n",
      "Std  - Original: 1.07, Imputed: 1.05\n",
      "\n",
      "user_depth:\n",
      "Mean - Original: 2.88, Imputed: 2.88\n",
      "Std  - Original: 0.40, Imputed: 0.39\n",
      "\n",
      "city_development_index:\n",
      "Mean - Original: 2.56, Imputed: 2.40\n",
      "Std  - Original: 0.92, Imputed: 0.82\n",
      "\n",
      "var_1:\n",
      "Mean - Original: 0.42, Imputed: 0.42\n",
      "Std  - Original: 0.49, Imputed: 0.49\n",
      "\n",
      "is_click:\n",
      "Mean - Original: 0.07, Imputed: 0.07\n",
      "Std  - Original: 0.25, Imputed: 0.25\n"
     ]
    }
   ],
   "source": [
    "def validate_imputation(df_original, df_imputed):\n",
    "    \"\"\"Validates that imputation maintained reasonable distributions\"\"\"\n",
    "    for col in df_original.columns:\n",
    "        if col == 'product_category_2':  # skip intentionally non-imputed column\n",
    "            continue\n",
    "            \n",
    "        if pd.api.types.is_numeric_dtype(df_original[col]):\n",
    "            # check that means and stds are similar for numeric columns\n",
    "            orig_mean = df_original[col].mean()\n",
    "            imp_mean = df_imputed[col].mean()\n",
    "            orig_std = df_original[col].std()\n",
    "            imp_std = df_imputed[col].std()\n",
    "            \n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Mean - Original: {orig_mean:.2f}, Imputed: {imp_mean:.2f}\")\n",
    "            print(f\"Std  - Original: {orig_std:.2f}, Imputed: {imp_std:.2f}\")\n",
    "        \n",
    "        elif pd.api.types.is_object_dtype(df_original[col]):\n",
    "            # check value distributions for categorical columns\n",
    "            orig_dist = df_original[col].value_counts(normalize=True)\n",
    "            imp_dist = df_imputed[col].value_counts(normalize=True)\n",
    "            \n",
    "            print(f\"\\n{col} distribution:\")\n",
    "            print(\"Original vs Imputed:\")\n",
    "            print(pd.concat([orig_dist, imp_dist], axis=1, \n",
    "                          keys=['Original', 'Imputed']).head())\n",
    "            \n",
    "\n",
    "imputation_params = {\n",
    "    'demographics_defaults': {\n",
    "        'gender': 'Male',\n",
    "        'age_level': 3.0,\n",
    "        'user_depth': 3.0,\n",
    "        'user_group_id': 3.0\n",
    "    },\n",
    "    'city_development_mode': 2.0\n",
    "}\n",
    "\n",
    "# save for later use\n",
    "with open('imputation_params.json', 'w') as f:\n",
    "    json.dump(imputation_params, f)\n",
    "\n",
    "\n",
    "def print_imputation_summary(df_original, df_imputed):\n",
    "    \"\"\"Prints summary of imputation changes\"\"\"\n",
    "    total_missing_before = df_original.isnull().sum().sum()\n",
    "    total_missing_after = df_imputed.isnull().sum().sum()\n",
    "    \n",
    "    print(\"\\nImputation Summary:\")\n",
    "    print(f\"Total missing values before: {total_missing_before:,}\")\n",
    "    print(f\"Total missing values after: {total_missing_after:,}\")\n",
    "    print(f\"Total values imputed: {total_missing_before - total_missing_after:,}\")\n",
    "\n",
    "validate_imputation(df, df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above validation, we can see that:\n",
    "1. Our target feature \"is_click\" maintained exactly same means and std, meaning its integrity is preserved.\n",
    "2. All features maintain very similar proportions apart from the below; \"gender\" ratio slightly shifted but reasonably (Male: 88.3% â†’ 88.9%) but these small shifts are acceptable given the missingness rates.\n",
    "3. \"city_development_index\" shows the largest shift, but it's expected given its high missingness rate (27.6%) and our mode imputation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: creating new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Creates temporal features from DateTime column.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # basic time features\n",
    "    df['hour'] = df['DateTime'].dt.hour\n",
    "    df['day_of_week'] = df['DateTime'].dt.dayofweek\n",
    "    \n",
    "    # binary features\n",
    "    df['is_business_hours'] = df['hour'].between(9, 17).astype(int)\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['is_early_morning'] = df['hour'].between(2, 5).astype(int)\n",
    "    \n",
    "    # time of day as categorical with both raw and binned versions\n",
    "    df['time_of_day'] = pd.cut(\n",
    "        df['hour'],\n",
    "        bins=[-np.inf, 6, 12, 18, np.inf],\n",
    "        labels=['night', 'morning', 'afternoon', 'evening']\n",
    "    )\n",
    "    \n",
    "    # add hour bins for reduced cardinality in interactions\n",
    "    df['hour_bin'] = pd.cut(\n",
    "        df['hour'],\n",
    "        bins=[0, 4, 8, 12, 16, 20, 24],\n",
    "        labels=['dawn', 'early_morning', 'morning', 'afternoon', 'evening', 'night'],\n",
    "        include_lowest=True,  # include the lower bound\n",
    "        right=False  # make intervals left-inclusive and right-exclusive\n",
    "    )\n",
    "    \n",
    "    # holiday features\n",
    "    us_holidays = holidays.US()\n",
    "    df['date'] = df['DateTime'].dt.date\n",
    "    \n",
    "    # handle holidays with proper date handling\n",
    "    df['is_holiday'] = df['date'].apply(\n",
    "        lambda x: bool(us_holidays.get(x)) if pd.notna(x) else 0\n",
    "    ).astype(int)\n",
    "    \n",
    "    # near holiday feature (2 days before/after)\n",
    "    min_date = df['date'].min()\n",
    "    max_date = df['date'].max()\n",
    "    \n",
    "    # filter holidays to our date range\n",
    "    holiday_dates = [date for date in us_holidays.keys() \n",
    "                    if min_date <= date <= max_date]\n",
    "    \n",
    "    near_holiday_dates = set()\n",
    "    for holiday in holiday_dates:\n",
    "        near_holiday_dates.update([\n",
    "            holiday - timedelta(days=i) for i in range(1, 3)\n",
    "        ] + [\n",
    "            holiday + timedelta(days=i) for i in range(1, 3)\n",
    "        ])\n",
    "    \n",
    "    df['is_near_holiday'] = df['date'].apply(\n",
    "        lambda x: x in near_holiday_dates if pd.notna(x) else 0\n",
    "    ).astype(int)\n",
    "    \n",
    "    # clean up temporary column\n",
    "    df = df.drop('date', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_user_engagement_features(df):\n",
    "    \"\"\"\n",
    "    Creates user engagement features with improved statistical handling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # sort by user and time for accurate historical features\n",
    "    df = df.sort_values(['user_id', 'DateTime'])\n",
    "    \n",
    "    # historical CTR per user with smoothing\n",
    "    user_clicks = df.groupby('user_id')['is_click'].agg(['sum', 'count']).reset_index()\n",
    "    \n",
    "    # add Bayesian smoothing\n",
    "    global_ctr = df['is_click'].mean()\n",
    "    smoothing_factor = 10  # Adjust based on data volume\n",
    "    user_clicks['historical_user_ctr'] = (\n",
    "        (user_clicks['sum'] + smoothing_factor * global_ctr) / \n",
    "        (user_clicks['count'] + smoothing_factor)\n",
    "    )\n",
    "    df = df.merge(user_clicks[['user_id', 'historical_user_ctr']], \n",
    "                 on='user_id', how='left')\n",
    "    \n",
    "    # session counts with log transformation\n",
    "    df['session_count_user'] = df.groupby('user_id')['session_id'].transform('count')\n",
    "    df['session_count_log'] = np.log1p(df['session_count_user'])\n",
    "    \n",
    "    # create session count bins using the log-transformed values\n",
    "    df['session_count_bin'] = pd.qcut(\n",
    "        df['session_count_log'],  # use the log-transformed feature\n",
    "        q=5,  # quantile-based binning\n",
    "        labels=['VL', 'L', 'M', 'H', 'VH']\n",
    "    )\n",
    "    \n",
    "    # sessions per day with improved statistics\n",
    "    df['date'] = df['DateTime'].dt.date\n",
    "    sessions_per_day = df.groupby(['user_id', 'date']).size().reset_index()\n",
    "    avg_sessions = sessions_per_day.groupby('user_id')[0].agg(['mean', 'std']).reset_index()\n",
    "    avg_sessions.columns = ['user_id', 'sessions_per_day_mean', 'sessions_per_day_std']\n",
    "    avg_sessions['sessions_per_day_std'] = avg_sessions['sessions_per_day_std'].fillna(0)\n",
    "    df = df.merge(avg_sessions, on='user_id', how='left')\n",
    "    \n",
    "    # log transformation for sessions per day mean (optional, if skewed)\n",
    "    df['sessions_per_day_mean_log'] = np.log1p(df['sessions_per_day_mean'])\n",
    "\n",
    "    # time since last click\n",
    "    max_hours = 168  # 1 week\n",
    "    df['time_since_last_click'] = (\n",
    "        df['DateTime'] - df.groupby('user_id')['DateTime'].shift(1)\n",
    "    ).dt.total_seconds() / 3600\n",
    "    df['time_since_last_click'] = df['time_since_last_click'].fillna(max_hours)\n",
    "    \n",
    "    # click frequency in last 24h with vectorized implementation\n",
    "    df['prev_24h'] = df['DateTime'] - pd.Timedelta(hours=24)\n",
    "    df['click_frequency_24h'] = df.groupby('user_id').apply(\n",
    "        lambda group: group.apply(\n",
    "            lambda row: group[\n",
    "                (group['DateTime'] <= row['DateTime']) & \n",
    "                (group['DateTime'] >= row['prev_24h']) & \n",
    "                (group['is_click'] == 1)\n",
    "            ].shape[0],\n",
    "            axis=1\n",
    "        )\n",
    "    ).reset_index(level=0, drop=True)\n",
    "    \n",
    "    # log transform click frequency\n",
    "    df['click_frequency_24h_log'] = np.log1p(df['click_frequency_24h'])\n",
    "    \n",
    "    # improved engagement score using percentile ranks\n",
    "    engagement_features = [\n",
    "        'historical_user_ctr',\n",
    "        'session_count_log',  # log-transformed\n",
    "        'sessions_per_day_mean_log',  # log-transformed mean\n",
    "        'click_frequency_24h_log'  # log-transformed\n",
    "    ]\n",
    "    \n",
    "    # convert each component to percentile rank\n",
    "    for feature in engagement_features:\n",
    "        df[f'{feature}_rank'] = df[feature].rank(pct=True)\n",
    "    \n",
    "    # weighted combination of ranks\n",
    "    df['user_engagement_score'] = (\n",
    "        0.4 * df['historical_user_ctr_rank'] +\n",
    "        0.25 * df['session_count_log_rank'] +\n",
    "        0.25 * df['sessions_per_day_mean_log_rank'] +\n",
    "        0.1 * df['click_frequency_24h_log_rank']\n",
    "        )\n",
    "    \n",
    "    # clean up temporary columns\n",
    "    df = df.drop(['prev_24h', 'date'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_campaign_performance_features(df):\n",
    "    \"\"\"\n",
    "    Creates campaign performance features with improved variance handling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # campaign historical CTR with log transformation\n",
    "    campaign_stats = df.groupby('campaign_id')['is_click'].agg(['mean', 'count']).reset_index()\n",
    "    campaign_stats.columns = ['campaign_id', 'campaign_historical_ctr', 'campaign_impressions']\n",
    "    \n",
    "    # log transform CTR after scaling to percentage\n",
    "    campaign_stats['campaign_historical_ctr_log'] = np.log1p(campaign_stats['campaign_historical_ctr'] * 100)\n",
    "    df = df.merge(campaign_stats, on='campaign_id', how='left')\n",
    "    \n",
    "    # create binned versions of CTR features\n",
    "    unique_vals = df['campaign_historical_ctr'].dropna().unique()  # get unique quantiles\n",
    "    n_bins = min(5, len(unique_vals))\n",
    "    \n",
    "    # campaign-webpage combination with relative performance\n",
    "    campaign_webpage_stats = df.groupby(['campaign_id', 'webpage_id'])['is_click'].agg([\n",
    "        ('campaign_webpage_ctr', 'mean'),\n",
    "        ('webpage_impressions', 'count')\n",
    "    ]).reset_index()\n",
    "\n",
    "    \n",
    "    # calculate relative performance\n",
    "    campaign_avg = df.groupby('campaign_id')['is_click'].mean()\n",
    "    campaign_webpage_stats['campaign_webpage_relative'] = (\n",
    "        campaign_webpage_stats['campaign_webpage_ctr'] / \n",
    "        campaign_avg[campaign_webpage_stats['campaign_id']].values\n",
    "    )\n",
    "    \n",
    "    df = df.merge(\n",
    "        campaign_webpage_stats[['campaign_id', 'webpage_id', 'campaign_webpage_relative']], \n",
    "        on=['campaign_id', 'webpage_id'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # hourly performance with relative metrics\n",
    "    hourly_stats = df.groupby(['hour'])['is_click'].mean().reset_index()\n",
    "    hourly_stats.columns = ['hour', 'hour_ctr']\n",
    "    df = df.merge(hourly_stats, on='hour', how='left')\n",
    "    \n",
    "    campaign_hour_stats = df.groupby(['campaign_id', 'hour'])['is_click'].mean().reset_index()\n",
    "    campaign_hour_stats['campaign_hour_relative'] = (\n",
    "        campaign_hour_stats['is_click'] / \n",
    "        campaign_hour_stats.groupby('campaign_id')['is_click'].transform('mean')\n",
    "    )\n",
    "    \n",
    "    df = df.merge(\n",
    "        campaign_hour_stats[['campaign_id', 'hour', 'campaign_hour_relative']], \n",
    "        on=['campaign_id', 'hour'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # product performance with relative metrics\n",
    "    campaign_product_stats = df.groupby(['campaign_id', 'product_category_1'])['is_click'].agg([\n",
    "        ('campaign_product_ctr', 'mean'),\n",
    "        ('product_impressions', 'count')\n",
    "    ]).reset_index()\n",
    "    \n",
    "    campaign_product_stats['campaign_product_relative'] = (\n",
    "        campaign_product_stats['campaign_product_ctr'] / \n",
    "        campaign_avg[campaign_product_stats['campaign_id']].values\n",
    "    )\n",
    "    \n",
    "    df = df.merge(\n",
    "        campaign_product_stats[[\n",
    "            'campaign_id', 'product_category_1', 'campaign_product_relative'\n",
    "        ]], \n",
    "        on=['campaign_id', 'product_category_1'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # campaign success as percentile rank\n",
    "    df['campaign_success_percentile'] = df['campaign_historical_ctr'].rank(pct=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_interaction_features(df):\n",
    "    \"\"\"\n",
    "    Creates interaction features with improved cardinality handling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # time-based interactions using binned features\n",
    "    df['campaign_hour_bin'] = df['campaign_id'].astype(str) + '_' + df['hour_bin'].astype(str)\n",
    "    df['campaign_early_morning'] = df['campaign_id'] * df['is_early_morning']\n",
    "    \n",
    "    # user depth interactions with binned time\n",
    "    df['user_depth_time'] = df['user_depth'].astype(str) + '_' + df['time_of_day'].astype(str)\n",
    "    \n",
    "    # age-weekend interaction (keep numeric for modeling)\n",
    "    df['age_weekend'] = df['age_level'] * df['is_weekend']\n",
    "    \n",
    "    # user-based interactions\n",
    "    df['user_depth_age'] = df['user_depth'] * df['age_level']\n",
    "    \n",
    "    # session-time interaction using binned sessions\n",
    "    df['user_sessions_time'] = df['session_count_bin'].astype(str) + '_' + df['time_of_day'].astype(str)\n",
    "    \n",
    "    # demographic interactions\n",
    "    df['gender_age'] = df['gender'].astype(str) + '_' + df['age_level'].astype(str)\n",
    "    \n",
    "    # campaign interactions using relative performance\n",
    "    df['campaign_success_time'] = df['campaign_success_percentile'] * df['hour'].map(\n",
    "        df.groupby('hour')['is_click'].mean()\n",
    "    )\n",
    "    \n",
    "    # geographic interactions\n",
    "    df['city_business'] = df['city_development_index'] * df['is_business_hours']\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_all_features(df):\n",
    "    \"\"\"\n",
    "    Applies all feature engineering steps and returns both engineered features\n",
    "    and a list of features requiring scaling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Apply each feature engineering step\n",
    "    df = create_temporal_features(df)\n",
    "    df = create_user_engagement_features(df)\n",
    "    df = create_campaign_performance_features(df)\n",
    "    df = create_interaction_features(df)\n",
    "    \n",
    "    # identify features that need scaling\n",
    "    features_to_scale = [\n",
    "        'historical_user_ctr',\n",
    "        'session_count_log',\n",
    "        'sessions_per_day_mean',\n",
    "        'sessions_per_day_std',\n",
    "        'time_since_last_click',\n",
    "        'click_frequency_24h_log',\n",
    "        'user_engagement_score',\n",
    "        'campaign_historical_ctr_log',\n",
    "        'campaign_webpage_relative',\n",
    "        'campaign_hour_relative',\n",
    "        'campaign_product_relative',\n",
    "        'campaign_success_percentile',\n",
    "        'user_depth_age',\n",
    "        'age_weekend',\n",
    "        'city_business',\n",
    "        'campaign_success_time'\n",
    "    ]\n",
    "    \n",
    "    return df, features_to_scale\n",
    "\n",
    "\n",
    "df_engineered, features_to_scale = create_all_features(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the completness of the new features, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Validation Results:\n",
      "--------------------------------------------------\n",
      "\n",
      "Features with null values:\n",
      "  product_category_2: 292615 nulls\n",
      "\n",
      "Features with very low variance:\n",
      "  historical_user_ctr: 0.001365\n",
      "  campaign_historical_ctr: 0.000229\n",
      "  campaign_webpage_relative: 0.001061\n",
      "  hour_ctr: 0.000012\n",
      "  campaign_success_time: 0.000370\n",
      "\n",
      "CTR features with invalid ranges:\n",
      "  campaign_historical_ctr_log: range [1.702, 2.314]\n"
     ]
    }
   ],
   "source": [
    "def validate_engineered_features(df):\n",
    "    \"\"\"\n",
    "    Performs sanity checks on engineered features.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # check for nulls\n",
    "    null_counts = df.isnull().sum()\n",
    "    results['features_with_nulls'] = null_counts[null_counts > 0].to_dict()\n",
    "    \n",
    "    # check for infinite values\n",
    "    inf_counts = df.isin([np.inf, -np.inf]).sum()\n",
    "    results['features_with_inf'] = inf_counts[inf_counts > 0].to_dict()\n",
    "    \n",
    "    # validate binary features are actually binary\n",
    "    binary_features = [col for col in df.columns if col.startswith('is_')]\n",
    "    non_binary = {col: sorted(df[col].unique()) \n",
    "                 for col in binary_features \n",
    "                 if not df[col].isin([0, 1, np.nan]).all()}\n",
    "    results['non_binary_features'] = non_binary\n",
    "    \n",
    "    # check for low variance features\n",
    "    variances = df.select_dtypes(include=np.number).var()\n",
    "    low_variance = variances[variances < 0.01].to_dict()\n",
    "    results['low_variance_features'] = low_variance\n",
    "    \n",
    "    # validate time-based features\n",
    "    if 'hour' in df.columns:\n",
    "        results['hour_range_valid'] = df['hour'].between(0, 23).all()\n",
    "    if 'day_of_week' in df.columns:\n",
    "        results['day_range_valid'] = df['day_of_week'].between(0, 6).all()\n",
    "        \n",
    "    # check for correct CTR ranges (between 0 and 1)\n",
    "    ctr_features = [col for col in df.columns if 'ctr' in col.lower()]\n",
    "    invalid_ctr = {col: (df[col].min(), df[col].max()) \n",
    "                  for col in ctr_features \n",
    "                  if not df[col].between(0, 1, inclusive='both').all()}\n",
    "    results['invalid_ctr_ranges'] = invalid_ctr\n",
    "    \n",
    "    # cardinality check for categorical features\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    high_cardinality = {col: df[col].nunique() \n",
    "                       for col in categorical_cols \n",
    "                       if df[col].nunique() > 100}\n",
    "    results['high_cardinality_features'] = high_cardinality\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def print_validation_results(results: dict):\n",
    "    \"\"\"\n",
    "    Prints validation results in a readable format.\n",
    "    \"\"\"\n",
    "    print(\"Feature Validation Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if results['features_with_nulls']:\n",
    "        print(\"\\nFeatures with null values:\")\n",
    "        for feat, count in results['features_with_nulls'].items():\n",
    "            print(f\"  {feat}: {count} nulls\")\n",
    "    \n",
    "    if results['features_with_inf']:\n",
    "        print(\"\\nFeatures with infinite values:\")\n",
    "        for feat, count in results['features_with_inf'].items():\n",
    "            print(f\"  {feat}: {count} infinities\")\n",
    "    \n",
    "    if results['non_binary_features']:\n",
    "        print(\"\\nNon-binary 'is_' features:\")\n",
    "        for feat, values in results['non_binary_features'].items():\n",
    "            print(f\"  {feat}: {values}\")\n",
    "    \n",
    "    if results['low_variance_features']:\n",
    "        print(\"\\nFeatures with very low variance:\")\n",
    "        for feat, var in results['low_variance_features'].items():\n",
    "            print(f\"  {feat}: {var:.6f}\")\n",
    "    \n",
    "    if results['invalid_ctr_ranges']:\n",
    "        print(\"\\nCTR features with invalid ranges:\")\n",
    "        for feat, (min_val, max_val) in results['invalid_ctr_ranges'].items():\n",
    "            print(f\"  {feat}: range [{min_val:.3f}, {max_val:.3f}]\")\n",
    "    \n",
    "    if results['high_cardinality_features']:\n",
    "        print(\"\\nHigh cardinality categorical features:\")\n",
    "        for feat, count in results['high_cardinality_features'].items():\n",
    "            print(f\"  {feat}: {count} unique values\")\n",
    "\n",
    "\n",
    "validation_results = validate_engineered_features(df_engineered)\n",
    "print_validation_results(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: These columns are not categorized: {'click_frequency_24h', 'session_count_user'}\n"
     ]
    }
   ],
   "source": [
    "def prepare_features_for_modeling(df, categorical_features, features_to_scale, keep_as_is):\n",
    "    \"\"\"\n",
    "    Prepares features for modeling by handling categorical and numerical variables.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # verify all features are accounted for\n",
    "    all_features = set(categorical_features + features_to_scale + keep_as_is)\n",
    "    missing_features = set(df.columns) - all_features\n",
    "    extra_features = all_features - set(df.columns)\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"Warning: These columns are not categorized: {missing_features}\")\n",
    "    if extra_features:\n",
    "        print(f\"Warning: These categorized features are not in dataframe: {extra_features}\")\n",
    "    \n",
    "    # ordinal encoding for ordinal features\n",
    "    ordinal_features = {\n",
    "        'age_level': range(7),\n",
    "        'user_depth': range(1, 4),\n",
    "        'city_development_index': range(1, 5)\n",
    "    }\n",
    "    \n",
    "    for col, categories in ordinal_features.items():\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.Categorical(df[col], categories=categories, ordered=True).codes\n",
    "    \n",
    "    # one-hot encoding for categorical features\n",
    "    for col in categorical_features:\n",
    "        if col in df.columns:\n",
    "            dummies = pd.get_dummies(df[col], prefix=col, drop_first=True)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "            df = df.drop(col, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "categorical_features = [\n",
    "    # Base categorical features\n",
    "    'gender', \n",
    "    'product',\n",
    "    \n",
    "    # Temporal categoricals\n",
    "    'time_of_day',    # night/morning/afternoon/evening\n",
    "    'hour_bin',       # dawn/early_morning/morning/afternoon/evening/night\n",
    "    \n",
    "    # Binned features\n",
    "    'session_count_bin',  # VL/L/M/H/VH\n",
    "    \n",
    "    # Interaction categoricals\n",
    "    'campaign_hour_bin',  # campaign_id + hour_bin\n",
    "    'user_depth_time',    # user_depth + time_of_day\n",
    "    'user_sessions_time', # session_count_bin + time_of_day\n",
    "    'gender_age'         # gender + age_level\n",
    "]\n",
    "\n",
    "features_to_scale = [\n",
    "    # User engagement metrics\n",
    "    'historical_user_ctr',\n",
    "    'session_count_log',\n",
    "    'sessions_per_day_mean',\n",
    "    'sessions_per_day_std',\n",
    "    'sessions_per_day_mean_log',\n",
    "    'time_since_last_click',\n",
    "    'click_frequency_24h_log',\n",
    "    'user_engagement_score',\n",
    "    \n",
    "    # Ranking features\n",
    "    'historical_user_ctr_rank',\n",
    "    'session_count_log_rank',\n",
    "    'sessions_per_day_mean_log_rank',\n",
    "    'click_frequency_24h_log_rank',\n",
    "    \n",
    "    # Campaign performance metrics\n",
    "    'campaign_historical_ctr',\n",
    "    'campaign_historical_ctr_log',\n",
    "    'campaign_webpage_relative',\n",
    "    'campaign_hour_relative',\n",
    "    'campaign_product_relative',\n",
    "    'campaign_success_percentile',\n",
    "    'hour_ctr',  # Added\n",
    "    \n",
    "    # Interaction numerics\n",
    "    'user_depth_age',\n",
    "    'age_weekend',\n",
    "    'city_business',\n",
    "    'campaign_success_time',\n",
    "    'campaign_early_morning'\n",
    "]\n",
    "\n",
    "keep_as_is = [\n",
    "    # IDs and timestamps\n",
    "    'session_id',\n",
    "    'user_id',\n",
    "    'campaign_id',\n",
    "    'webpage_id',\n",
    "    'DateTime',  # Added\n",
    "    \n",
    "    # Target\n",
    "    'is_click',\n",
    "    \n",
    "    # Binary features\n",
    "    'is_business_hours',\n",
    "    'is_weekend',\n",
    "    'is_early_morning',\n",
    "    'is_holiday',\n",
    "    'is_near_holiday',\n",
    "    'product_category_2_missing',\n",
    "    'city_development_missing',\n",
    "    'var_1',  # Added\n",
    "    \n",
    "    # Time features in fixed ranges\n",
    "    'hour',         # 0-23\n",
    "    'day_of_week',  # 0-6\n",
    "    \n",
    "    # Ordinal features\n",
    "    'age_level',           # 0-6\n",
    "    'user_depth',          # 1-3\n",
    "    'city_development_index', # 1-4\n",
    "    \n",
    "    # Other features\n",
    "    'product_category_1',  # 1-5\n",
    "    'product_category_2',  # Added (kept as-is due to high missingness)\n",
    "    'user_group_id',      # Added (derived from age and gender)\n",
    "    'campaign_impressions'\n",
    "]\n",
    "\n",
    "\n",
    "# prepare the features for modeling by encoding categorical variables\n",
    "df_prepared = prepare_features_for_modeling(\n",
    "    df_engineered, \n",
    "    categorical_features, \n",
    "    features_to_scale, \n",
    "    keep_as_is\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilter_features(df: pd.DataFrame, target_col: str = 'is_click', verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Multi-stage feature pre-filtering process.\n",
    "    Returns a list of features that pass all filtering stages.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    initial_features = len(df.columns) - 1  # exclude target\n",
    "    if verbose:\n",
    "        print(f\"Starting with {initial_features} features\")\n",
    "    \n",
    "    # remove constant and quasi-constant features\n",
    "    def remove_low_variance_features(df, threshold=0.01):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        variances = df[numeric_cols].var()\n",
    "        low_var_features = variances[variances < threshold].index.tolist()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nLow variance features removed ({len(low_var_features)}):\")\n",
    "            for f in low_var_features:\n",
    "                print(f\"- {f} (variance: {variances[f]:.6f})\")\n",
    "        \n",
    "        return df.drop(columns=low_var_features)\n",
    "\n",
    "    # remove highly correlated features\n",
    "    def remove_correlated_features(df, threshold=0.95):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        corr_matrix = df[numeric_cols].corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        \n",
    "        high_corr_features = []\n",
    "        seen_pairs = set()\n",
    "        \n",
    "        # find features to remove\n",
    "        for col in upper.columns:\n",
    "            # Get correlations above threshold\n",
    "            high_corr = upper[col][upper[col] > threshold].index.tolist()\n",
    "            for feat in high_corr:\n",
    "                if (col, feat) not in seen_pairs and (feat, col) not in seen_pairs:\n",
    "                    # Keep the one with higher correlation with target\n",
    "                    corr_with_target = abs(df[[col, feat, target_col]].corr()[target_col])\n",
    "                    if corr_with_target[col] < corr_with_target[feat]:\n",
    "                        high_corr_features.append(col)\n",
    "                    else:\n",
    "                        high_corr_features.append(feat)\n",
    "                    seen_pairs.add((col, feat))\n",
    "        \n",
    "        high_corr_features = list(set(high_corr_features))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nHighly correlated features removed ({len(high_corr_features)}):\")\n",
    "            for f in high_corr_features:\n",
    "                print(f\"- {f}\")\n",
    "        \n",
    "        return df.drop(columns=high_corr_features)\n",
    "\n",
    "    # remove features with low mutual information\n",
    "    def remove_low_mi_features(df, target_col, threshold=0.001):\n",
    "        # separate numeric and categorical columns\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_cols.remove(target_col)\n",
    "        \n",
    "        # calculate MI scores for numeric features\n",
    "        mi_scores = mutual_info_classif(\n",
    "            StandardScaler().fit_transform(df[numeric_cols]), \n",
    "            df[target_col],\n",
    "            random_state=42\n",
    "        )\n",
    "        mi_series = pd.Series(mi_scores, index=numeric_cols)\n",
    "        \n",
    "        # identify features with low MI scores\n",
    "        low_mi_features = mi_series[mi_series < threshold].index.tolist()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nLow mutual information features removed ({len(low_mi_features)}):\")\n",
    "            for f in low_mi_features:\n",
    "                print(f\"- {f} (MI score: {mi_series[f]:.6f})\")\n",
    "        \n",
    "        return df.drop(columns=low_mi_features)\n",
    "\n",
    "    # remove features with high p-value in univariate testing\n",
    "    def remove_insignificant_features(df, target_col, p_threshold=0.05):\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_cols.remove(target_col)\n",
    "        \n",
    "        insignificant_features = []\n",
    "        for col in numeric_cols:\n",
    "            _, p_value = stats.mannwhitneyu(\n",
    "                df[df[target_col] == 1][col],\n",
    "                df[df[target_col] == 0][col],\n",
    "                alternative='two-sided'\n",
    "            )\n",
    "            if p_value > p_threshold:\n",
    "                insignificant_features.append(col)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nStatistically insignificant features removed ({len(insignificant_features)}):\")\n",
    "            for f in insignificant_features:\n",
    "                print(f\"- {f}\")\n",
    "        \n",
    "        return df.drop(columns=insignificant_features)\n",
    "\n",
    "\n",
    "    # apply all filtering stages\n",
    "    df = remove_low_variance_features(df)\n",
    "    df = remove_correlated_features(df)\n",
    "    df = remove_low_mi_features(df, target_col)\n",
    "    df = remove_insignificant_features(df, target_col)\n",
    "    \n",
    "    selected_features = [col for col in df.columns if col != target_col]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFinal feature set: {len(selected_features)} features\")\n",
    "        print(\"\\nRemaining features:\")\n",
    "        for f in selected_features:\n",
    "            print(f\"- {f}\")\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 171 features\n",
      "\n",
      "Low variance features removed (33):\n",
      "- historical_user_ctr (variance: 0.001365)\n",
      "- campaign_historical_ctr (variance: 0.000229)\n",
      "- campaign_webpage_relative (variance: 0.001061)\n",
      "- hour_ctr (variance: 0.000012)\n",
      "- campaign_success_time (variance: 0.000370)\n",
      "- campaign_hour_bin_105960.0_dawn (variance: 0.002765)\n",
      "- campaign_hour_bin_105960.0_evening (variance: 0.008292)\n",
      "- campaign_hour_bin_105960.0_night (variance: 0.005713)\n",
      "- campaign_hour_bin_118601.0_dawn (variance: 0.002693)\n",
      "- campaign_hour_bin_359520.0_dawn (variance: 0.005111)\n",
      "- campaign_hour_bin_360936.0_dawn (variance: 0.003241)\n",
      "- campaign_hour_bin_396664.0_afternoon (variance: 0.009901)\n",
      "- campaign_hour_bin_396664.0_dawn (variance: 0.001898)\n",
      "- campaign_hour_bin_396664.0_early_morning (variance: 0.007651)\n",
      "- campaign_hour_bin_396664.0_morning (variance: 0.008215)\n",
      "- campaign_hour_bin_404347.0_dawn (variance: 0.002617)\n",
      "- campaign_hour_bin_404347.0_early_morning (variance: 0.009052)\n",
      "- campaign_hour_bin_405490.0_dawn (variance: 0.002975)\n",
      "- campaign_hour_bin_414149.0_dawn (variance: 0.000216)\n",
      "- campaign_hour_bin_414149.0_early_morning (variance: 0.006098)\n",
      "- campaign_hour_bin_414149.0_night (variance: 0.008462)\n",
      "- campaign_hour_bin_82320.0_dawn (variance: 0.000157)\n",
      "- campaign_hour_bin_82320.0_early_morning (variance: 0.003800)\n",
      "- campaign_hour_bin_98970.0_dawn (variance: 0.000406)\n",
      "- campaign_hour_bin_98970.0_early_morning (variance: 0.009180)\n",
      "- user_depth_time_1.0_evening (variance: 0.005948)\n",
      "- user_depth_time_1.0_morning (variance: 0.008422)\n",
      "- user_depth_time_1.0_night (variance: 0.002698)\n",
      "- user_depth_time_2.0_night (variance: 0.007445)\n",
      "- gender_age_Female_1.0 (variance: 0.003091)\n",
      "- gender_age_Female_6.0 (variance: 0.002283)\n",
      "- gender_age_Male_0.0 (variance: 0.000268)\n",
      "- gender_age_Male_6.0 (variance: 0.003749)\n",
      "\n",
      "Highly correlated features removed (3):\n",
      "- campaign_success_percentile\n",
      "- session_count_user\n",
      "- sessions_per_day_std\n",
      "\n",
      "Low mutual information features removed (0):\n",
      "\n",
      "Statistically insignificant features removed (26):\n",
      "- user_id\n",
      "- user_depth\n",
      "- city_development_missing\n",
      "- is_business_hours\n",
      "- is_near_holiday\n",
      "- city_business\n",
      "- product_C\n",
      "- product_E\n",
      "- time_of_day_afternoon\n",
      "- hour_bin_afternoon\n",
      "- hour_bin_evening\n",
      "- campaign_hour_bin_105960.0_early_morning\n",
      "- campaign_hour_bin_105960.0_morning\n",
      "- campaign_hour_bin_396664.0_evening\n",
      "- campaign_hour_bin_396664.0_night\n",
      "- campaign_hour_bin_404347.0_night\n",
      "- campaign_hour_bin_82320.0_afternoon\n",
      "- campaign_hour_bin_82320.0_morning\n",
      "- campaign_hour_bin_98970.0_afternoon\n",
      "- user_depth_time_2.0_morning\n",
      "- user_depth_time_3.0_afternoon\n",
      "- user_depth_time_3.0_evening\n",
      "- user_depth_time_3.0_night\n",
      "- user_sessions_time_M_night\n",
      "- gender_age_Female_2.0\n",
      "- gender_age_Female_3.0\n",
      "\n",
      "Final feature set: 109 features\n",
      "\n",
      "Remaining features:\n",
      "- session_id\n",
      "- DateTime\n",
      "- campaign_id\n",
      "- webpage_id\n",
      "- product_category_1\n",
      "- user_group_id\n",
      "- age_level\n",
      "- city_development_index\n",
      "- var_1\n",
      "- product_category_2_missing\n",
      "- hour\n",
      "- day_of_week\n",
      "- is_weekend\n",
      "- is_early_morning\n",
      "- is_holiday\n",
      "- session_count_log\n",
      "- sessions_per_day_mean\n",
      "- sessions_per_day_mean_log\n",
      "- time_since_last_click\n",
      "- click_frequency_24h\n",
      "- click_frequency_24h_log\n",
      "- historical_user_ctr_rank\n",
      "- session_count_log_rank\n",
      "- sessions_per_day_mean_log_rank\n",
      "- click_frequency_24h_log_rank\n",
      "- user_engagement_score\n",
      "- campaign_impressions\n",
      "- campaign_historical_ctr_log\n",
      "- campaign_hour_relative\n",
      "- campaign_product_relative\n",
      "- campaign_early_morning\n",
      "- age_weekend\n",
      "- user_depth_age\n",
      "- gender_Male\n",
      "- product_B\n",
      "- product_D\n",
      "- product_F\n",
      "- product_G\n",
      "- product_H\n",
      "- product_I\n",
      "- product_J\n",
      "- time_of_day_morning\n",
      "- time_of_day_evening\n",
      "- hour_bin_early_morning\n",
      "- hour_bin_morning\n",
      "- hour_bin_night\n",
      "- session_count_bin_L\n",
      "- session_count_bin_M\n",
      "- session_count_bin_H\n",
      "- session_count_bin_VH\n",
      "- campaign_hour_bin_118601.0_afternoon\n",
      "- campaign_hour_bin_118601.0_early_morning\n",
      "- campaign_hour_bin_118601.0_evening\n",
      "- campaign_hour_bin_118601.0_morning\n",
      "- campaign_hour_bin_118601.0_night\n",
      "- campaign_hour_bin_359520.0_afternoon\n",
      "- campaign_hour_bin_359520.0_early_morning\n",
      "- campaign_hour_bin_359520.0_evening\n",
      "- campaign_hour_bin_359520.0_morning\n",
      "- campaign_hour_bin_359520.0_night\n",
      "- campaign_hour_bin_360936.0_afternoon\n",
      "- campaign_hour_bin_360936.0_early_morning\n",
      "- campaign_hour_bin_360936.0_evening\n",
      "- campaign_hour_bin_360936.0_morning\n",
      "- campaign_hour_bin_360936.0_night\n",
      "- campaign_hour_bin_404347.0_afternoon\n",
      "- campaign_hour_bin_404347.0_evening\n",
      "- campaign_hour_bin_404347.0_morning\n",
      "- campaign_hour_bin_405490.0_afternoon\n",
      "- campaign_hour_bin_405490.0_early_morning\n",
      "- campaign_hour_bin_405490.0_evening\n",
      "- campaign_hour_bin_405490.0_morning\n",
      "- campaign_hour_bin_405490.0_night\n",
      "- campaign_hour_bin_414149.0_afternoon\n",
      "- campaign_hour_bin_414149.0_evening\n",
      "- campaign_hour_bin_414149.0_morning\n",
      "- campaign_hour_bin_82320.0_evening\n",
      "- campaign_hour_bin_82320.0_night\n",
      "- campaign_hour_bin_98970.0_evening\n",
      "- campaign_hour_bin_98970.0_morning\n",
      "- campaign_hour_bin_98970.0_night\n",
      "- user_depth_time_2.0_afternoon\n",
      "- user_depth_time_2.0_evening\n",
      "- user_depth_time_3.0_morning\n",
      "- user_sessions_time_H_evening\n",
      "- user_sessions_time_H_morning\n",
      "- user_sessions_time_H_night\n",
      "- user_sessions_time_L_afternoon\n",
      "- user_sessions_time_L_evening\n",
      "- user_sessions_time_L_morning\n",
      "- user_sessions_time_L_night\n",
      "- user_sessions_time_M_afternoon\n",
      "- user_sessions_time_M_evening\n",
      "- user_sessions_time_M_morning\n",
      "- user_sessions_time_VH_afternoon\n",
      "- user_sessions_time_VH_evening\n",
      "- user_sessions_time_VH_morning\n",
      "- user_sessions_time_VH_night\n",
      "- user_sessions_time_VL_afternoon\n",
      "- user_sessions_time_VL_evening\n",
      "- user_sessions_time_VL_morning\n",
      "- user_sessions_time_VL_night\n",
      "- gender_age_Female_4.0\n",
      "- gender_age_Female_5.0\n",
      "- gender_age_Male_1.0\n",
      "- gender_age_Male_2.0\n",
      "- gender_age_Male_3.0\n",
      "- gender_age_Male_4.0\n",
      "- gender_age_Male_5.0\n"
     ]
    }
   ],
   "source": [
    "# convert boolean columns to integers\n",
    "bool_cols = df_prepared.select_dtypes(include='bool').columns\n",
    "df_prepared[bool_cols] = df_prepared[bool_cols].astype(int)\n",
    "\n",
    "# omit the \"product_category_2\" feature as it has high missingness and was replaced\n",
    "# by a binary indicator\n",
    "df_prepared = df_prepared.drop('product_category_2', axis=1)\n",
    "\n",
    "# run through the pre-filtering process to see its suggestions\n",
    "selected_features = prefilter_features(df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns to drop\n",
    "base_cols_to_drop = ['is_click', 'DateTime', 'session_id', 'user_id', \n",
    "                     'sessions_per_day_std', 'historical_user_ctr', 'session_count_log_rank', \n",
    "                     'sessions_per_day_mean_log_rank', 'click_frequency_24h_log_rank',\n",
    "                     'session_count_user', 'sessions_per_day_mean', 'click_frequency_24h', \n",
    "                     'campaign_historical_ctr']\n",
    "\n",
    "# get pattern-matched columns\n",
    "user_sessions_time_cols = [col for col in df_prepared.columns if 'user_sessions_time_' in col]\n",
    "campaign_hour_bin_cols = [col for col in df_prepared.columns if 'campaign_hour_bin_' in col]\n",
    "time_of_day_cols = [col for col in df_prepared.columns if 'time_of_day_' in col]\n",
    "\n",
    "# combine all columns to drop\n",
    "all_cols_to_drop = base_cols_to_drop + user_sessions_time_cols + campaign_hour_bin_cols + time_of_day_cols\n",
    "\n",
    "# update the selected features list to exclude the columns to drop\n",
    "selected_features = [col for col in selected_features if col not in all_cols_to_drop]\n",
    "\n",
    "# remove these from the \"categorical_features\", \"features_to_scale\", and \"keep_as_is\" lists\n",
    "categorical_features = [col for col in categorical_features if col not in all_cols_to_drop]\n",
    "features_to_scale = [col for col in features_to_scale if col not in all_cols_to_drop]\n",
    "keep_as_is = [col for col in keep_as_is if col not in all_cols_to_drop]\n",
    "\n",
    "# safely drop columns and split data- if the columns are not present, it will not raise an error\n",
    "y = df_prepared['is_click']\n",
    "X = df_prepared.drop(all_cols_to_drop, axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features that need it, by training the scaler on the training set\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_importance_optimized(X, y, n_bootstraps=100, sample_size=None):\n",
    "    if sample_size is None:\n",
    "        sample_size = len(X)\n",
    "\n",
    "    mi_scores = np.zeros((n_bootstraps, X.shape[1]), dtype=np.float32)\n",
    "    rf_importance = np.zeros((n_bootstraps, X.shape[1]), dtype=np.float32)\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        n_estimators=30,\n",
    "        max_depth=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    indices_cache = np.random.randint(0, len(X), size=(n_bootstraps, sample_size))\n",
    "    for i, indices in enumerate(indices_cache):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Bootstrap iteration {i}/{n_bootstraps}\")\n",
    "\n",
    "        X_boot, y_boot = X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "        mi_scores[i] = mutual_info_classif(X_boot, y_boot, random_state=42)\n",
    "        rf.fit(X_boot, y_boot)\n",
    "        rf_importance[i] = rf.feature_importances_\n",
    "\n",
    "    mean_std_ci = lambda scores: (\n",
    "        scores.mean(),\n",
    "        scores.std(),\n",
    "        stats.norm.interval(0.95, scores.mean(), scores.std())\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    for j, feature in enumerate(X.columns):\n",
    "        mi_mean, mi_std, mi_ci = mean_std_ci(mi_scores[:, j])\n",
    "        rf_mean, rf_std, rf_ci = mean_std_ci(rf_importance[:, j])\n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'mi_score': mi_mean,\n",
    "            'mi_ci_lower': mi_ci[0],\n",
    "            'mi_ci_upper': mi_ci[1],\n",
    "            'rf_importance': rf_mean,\n",
    "            'rf_ci_lower': rf_ci[0],\n",
    "            'rf_ci_upper': rf_ci[1],\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def select_features_cv_optimized(X, y, base_features, threshold=0.01):\n",
    "    selected_features = base_features.copy()\n",
    "    remaining_features = [f for f in X.columns if f not in selected_features]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    estimator = RandomForestClassifier(\n",
    "        n_estimators=30,\n",
    "        max_depth=10,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    base_score = cross_val_score(\n",
    "        estimator,\n",
    "        X[selected_features],\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring='f1',\n",
    "    ).mean()\n",
    "\n",
    "    improved = True\n",
    "    while improved and remaining_features:\n",
    "        improved = False\n",
    "        scores = {}\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            score = cross_val_score(\n",
    "                estimator,\n",
    "                X[current_features],\n",
    "                y,\n",
    "                cv=cv,\n",
    "                scoring='f1',\n",
    "                n_jobs=-1,\n",
    "            ).mean()\n",
    "            scores[feature] = score\n",
    "\n",
    "        best_feature, best_score = max(scores.items(), key=lambda x: x[1])\n",
    "        if best_score > base_score + threshold:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            base_score = best_score\n",
    "            print(f\"Added {best_feature} (new f1: {best_score:.4f})\")\n",
    "            improved = True\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "def select_features_optimized(X_train_scaled, y_train, X_test_scaled=None):\n",
    "\n",
    "    importance_df = evaluate_feature_importance_optimized(X_train_scaled, y_train)\n",
    "\n",
    "    stable_features = importance_df[\n",
    "        (importance_df['mi_ci_lower'] > 0) &\n",
    "        (importance_df['rf_ci_lower'] > 0)\n",
    "    ]['feature'].tolist()\n",
    "\n",
    "    print(f\"\\nFound {len(stable_features)} stable features\")\n",
    "\n",
    "    base_features = importance_df[\n",
    "        (importance_df['mi_score'] > importance_df['mi_score'].median()) &\n",
    "        (importance_df['rf_importance'] > importance_df['rf_importance'].median())\n",
    "    ]['feature'].tolist()\n",
    "\n",
    "    selected_features = select_features_cv_optimized(\n",
    "        X_train_scaled[stable_features],\n",
    "        y_train,\n",
    "        base_features,\n",
    "    )\n",
    "\n",
    "    print(\"\\nFeature Selection Summary:\")\n",
    "    print(f\"Initial features: {X_train_scaled.shape[1]}\")\n",
    "    print(f\"Stable features: {len(stable_features)}\")\n",
    "    print(f\"Final selected features: {len(selected_features)}\")\n",
    "\n",
    "    return selected_features, importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap iteration 0/100\n",
      "Bootstrap iteration 10/100\n",
      "Bootstrap iteration 20/100\n",
      "Bootstrap iteration 30/100\n",
      "Bootstrap iteration 40/100\n",
      "Bootstrap iteration 50/100\n",
      "Bootstrap iteration 60/100\n",
      "Bootstrap iteration 70/100\n",
      "Bootstrap iteration 80/100\n",
      "Bootstrap iteration 90/100\n",
      "\n",
      "Found 58 stable features\n",
      "\n",
      "Feature Selection Summary:\n",
      "Initial features: 78\n",
      "Stable features: 58\n",
      "Final selected features: 28\n",
      "\n",
      "Selected Features:\n",
      "['campaign_id', 'webpage_id', 'product_category_1', 'user_group_id', 'age_level', 'city_development_index', 'var_1', 'city_development_missing', 'day_of_week', 'is_near_holiday', 'session_count_log', 'sessions_per_day_mean_log', 'time_since_last_click', 'click_frequency_24h_log', 'historical_user_ctr_rank', 'user_engagement_score', 'campaign_impressions', 'campaign_historical_ctr_log', 'campaign_success_percentile', 'campaign_early_morning', 'age_weekend', 'user_depth_age', 'city_business', 'product_C', 'product_H', 'session_count_bin_H', 'session_count_bin_VH', 'gender_age_Male_3.0']\n",
      "\n",
      "Feature Importance DataFrame:\n",
      "                     feature  mi_score  mi_ci_lower  mi_ci_upper  \\\n",
      "20   click_frequency_24h_log  0.159914     0.158194     0.161633   \n",
      "22     user_engagement_score  0.175302     0.173347     0.177258   \n",
      "21  historical_user_ctr_rank  0.137131     0.135328     0.138934   \n",
      "19     time_since_last_click  0.020828     0.019686     0.021971   \n",
      "17         session_count_log  0.006845     0.005939     0.007751   \n",
      "\n",
      "    rf_importance  rf_ci_lower  rf_ci_upper  \n",
      "20       0.360314     0.313929     0.406699  \n",
      "22       0.215313     0.183104     0.247522  \n",
      "21       0.190158     0.145470     0.234847  \n",
      "19       0.067733     0.056680     0.078785  \n",
      "17       0.064417     0.051637     0.077198  \n"
     ]
    }
   ],
   "source": [
    "# call the optimized feature selection function\n",
    "selected_features, importance_df = select_features_optimized(X_train_scaled, y_train, X_test_scaled)\n",
    "\n",
    "# review results\n",
    "print(\"\\nSelected Features:\")\n",
    "print(selected_features)\n",
    "\n",
    "print(\"\\nFeature Importance DataFrame:\")\n",
    "print(importance_df.sort_values(by='rf_importance', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = ['campaign_id', 'webpage_id', 'product_category_1', 'user_group_id', 'age_level', \n",
    "                 'city_development_index', 'var_1', 'city_development_missing', 'day_of_week', \n",
    "                 'is_near_holiday', 'session_count_log', 'sessions_per_day_mean_log', \n",
    "                 'time_since_last_click', 'click_frequency_24h_log', 'historical_user_ctr_rank', \n",
    "                 'user_engagement_score', 'campaign_impressions', 'campaign_historical_ctr_log', \n",
    "                 'campaign_success_percentile', 'campaign_early_morning', 'age_weekend', \n",
    "                 'user_depth_age', 'city_business', 'product_C', 'product_H', 'session_count_bin_H', \n",
    "                 'session_count_bin_VH', 'gender_age_Male_3.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results:\n",
      "--------------------------------------------------\n",
      "ROC AUC Score: 0.9711\n",
      "Average Precision Score: 0.5495\n",
      "Cross-validation ROC AUC: 0.9702 (+/- 0.0016)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.93      0.96     68969\n",
      "         1.0       0.49      0.97      0.65      4962\n",
      "\n",
      "    accuracy                           0.93     73931\n",
      "   macro avg       0.74      0.95      0.80     73931\n",
      "weighted avg       0.96      0.93      0.94     73931\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "--------------------------------------------------\n",
      "ROC AUC Score: 0.9875\n",
      "Average Precision Score: 0.8669\n",
      "Cross-validation ROC AUC: 0.9866 (+/- 0.0007)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.96     68969\n",
      "         1.0       0.47      0.99      0.63      4962\n",
      "\n",
      "    accuracy                           0.92     73931\n",
      "   macro avg       0.73      0.95      0.80     73931\n",
      "weighted avg       0.96      0.92      0.94     73931\n",
      "\n",
      "\n",
      "Gradient Boosting Results:\n",
      "--------------------------------------------------\n",
      "ROC AUC Score: 0.9881\n",
      "Average Precision Score: 0.8772\n",
      "Cross-validation ROC AUC: 0.9874 (+/- 0.0008)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98     68969\n",
      "         1.0       0.86      0.67      0.75      4962\n",
      "\n",
      "    accuracy                           0.97     73931\n",
      "   macro avg       0.92      0.83      0.87     73931\n",
      "weighted avg       0.97      0.97      0.97     73931\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                        feature  importance\n",
      "13      click_frequency_24h_log    0.581888\n",
      "12        time_since_last_click    0.324116\n",
      "11    sessions_per_day_mean_log    0.038528\n",
      "14     historical_user_ctr_rank    0.026255\n",
      "15        user_engagement_score    0.009552\n",
      "10            session_count_log    0.003509\n",
      "2            product_category_1    0.002119\n",
      "16         campaign_impressions    0.001520\n",
      "0                   campaign_id    0.001319\n",
      "17  campaign_historical_ctr_log    0.001256\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # calculate metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "    print(f\"Average Precision Score: {avg_precision:.4f}\")\n",
    "    print(f\"Cross-validation ROC AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# keep only selected features in train and test sets\n",
    "X_train_final = X_train_scaled[selected_features]\n",
    "X_test_final = X_test_scaled[selected_features]\n",
    "\n",
    "\n",
    "# logistic regression\n",
    "lr_model = evaluate_model(\n",
    "    LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    X_train_final, X_test_final, y_train, y_test,\n",
    "    \"Logistic Regression\"\n",
    ")\n",
    "\n",
    "# random forest\n",
    "rf_model = evaluate_model(\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    X_train_final, X_test_final, y_train, y_test,\n",
    "    \"Random Forest\"\n",
    ")\n",
    "\n",
    "# gradient boosting\n",
    "gb_model = evaluate_model(\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    X_train_final, X_test_final, y_train, y_test,\n",
    "    \"Gradient Boosting\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train_final, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_final, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': ['logloss', 'auc'],\n",
    "    'seed': 42,\n",
    "    # Add only minimal adjustments\n",
    "    'min_child_weight': 3,  # Helps prevent overfitting\n",
    "    'subsample': 0.9,      # Slight randomness\n",
    "    'colsample_bytree': 0.9  # Slight feature sampling\n",
    "}\n",
    "\n",
    "\n",
    "# xgboost model\n",
    "xgb_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=200,\n",
    "    evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "    early_stopping_rounds=20,\n",
    "    verbose_eval=50\n",
    ")\n",
    "\n",
    "# cross-validation\n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=1000,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=20,\n",
    "    metrics=['auc', 'logloss'],\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "--------------------------------------------------\n",
      "ROC AUC Score: 0.9885967890322466\n",
      "F1 Score: 0.7649889713254462\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98     68969\n",
      "         1.0       0.76      0.77      0.76      4962\n",
      "\n",
      "    accuracy                           0.97     73931\n",
      "   macro avg       0.87      0.88      0.87     73931\n",
      "weighted avg       0.97      0.97      0.97     73931\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                        feature   importance\n",
      "13      click_frequency_24h_log  2157.626953\n",
      "12        time_since_last_click   463.921417\n",
      "14     historical_user_ctr_rank   221.593262\n",
      "11    sessions_per_day_mean_log   130.092178\n",
      "15        user_engagement_score   104.153023\n",
      "10            session_count_log    38.393528\n",
      "18  campaign_success_percentile    20.707743\n",
      "24                    product_H     9.741928\n",
      "17  campaign_historical_ctr_log     9.685002\n",
      "23                    product_C     6.982815\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = xgb_model.predict(dtest)  # predict probabilities\n",
    "\n",
    "# find the optimal threshold for F1 score\n",
    "thresholds = np.arange(0.2, 0.8, 0.05)\n",
    "f1_scores = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba > threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_thresh))\n",
    "\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_optimal = (y_pred_proba > optimal_threshold).astype(int)\n",
    "\n",
    "y_pred = (y_pred_proba > optimal_threshold).astype(int)\n",
    "\n",
    "# feature importance\n",
    "importance_dict = xgb_model.get_score(importance_type='gain')\n",
    "importance_df = pd.DataFrame(\n",
    "    [(k, v) for k, v in importance_dict.items()],\n",
    "    columns=['feature', 'importance']\n",
    ").sort_values('importance', ascending=False)\n",
    "\n",
    "# print evaluation metrics\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
